{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b1fd94-716c-443d-a2df-d6afc8a098a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c8f5f-dc8a-48a2-94aa-505cd12e9722",
   "metadata": {},
   "source": [
    "## 1. 快速了解一个类和包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "573cada9-2028-4c2d-a03a-5c5c3cfc68c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy.linalg:\n",
      "\n",
      "svd(a, full_matrices=True, compute_uv=True, hermitian=False)\n",
      "    Singular Value Decomposition.\n",
      "    \n",
      "    When `a` is a 2D array, and ``full_matrices=False``, then it is\n",
      "    factorized as ``u @ np.diag(s) @ vh = (u * s) @ vh``, where\n",
      "    `u` and the Hermitian transpose of `vh` are 2D arrays with\n",
      "    orthonormal columns and `s` is a 1D array of `a`'s singular\n",
      "    values. When `a` is higher-dimensional, SVD is applied in\n",
      "    stacked mode as explained below.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : (..., M, N) array_like\n",
      "        A real or complex array with ``a.ndim >= 2``.\n",
      "    full_matrices : bool, optional\n",
      "        If True (default), `u` and `vh` have the shapes ``(..., M, M)`` and\n",
      "        ``(..., N, N)``, respectively.  Otherwise, the shapes are\n",
      "        ``(..., M, K)`` and ``(..., K, N)``, respectively, where\n",
      "        ``K = min(M, N)``.\n",
      "    compute_uv : bool, optional\n",
      "        Whether or not to compute `u` and `vh` in addition to `s`.  True\n",
      "        by default.\n",
      "    hermitian : bool, optional\n",
      "        If True, `a` is assumed to be Hermitian (symmetric if real-valued),\n",
      "        enabling a more efficient method for finding singular values.\n",
      "        Defaults to False.\n",
      "    \n",
      "        .. versionadded:: 1.17.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    When `compute_uv` is True, the result is a namedtuple with the following\n",
      "    attribute names:\n",
      "    \n",
      "    U : { (..., M, M), (..., M, K) } array\n",
      "        Unitary array(s). The first ``a.ndim - 2`` dimensions have the same\n",
      "        size as those of the input `a`. The size of the last two dimensions\n",
      "        depends on the value of `full_matrices`. Only returned when\n",
      "        `compute_uv` is True.\n",
      "    S : (..., K) array\n",
      "        Vector(s) with the singular values, within each vector sorted in\n",
      "        descending order. The first ``a.ndim - 2`` dimensions have the same\n",
      "        size as those of the input `a`.\n",
      "    Vh : { (..., N, N), (..., K, N) } array\n",
      "        Unitary array(s). The first ``a.ndim - 2`` dimensions have the same\n",
      "        size as those of the input `a`. The size of the last two dimensions\n",
      "        depends on the value of `full_matrices`. Only returned when\n",
      "        `compute_uv` is True.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    LinAlgError\n",
      "        If SVD computation does not converge.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.linalg.svd : Similar function in SciPy.\n",
      "    scipy.linalg.svdvals : Compute singular values of a matrix.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    \n",
      "    .. versionchanged:: 1.8.0\n",
      "       Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "       details.\n",
      "    \n",
      "    The decomposition is performed using LAPACK routine ``_gesdd``.\n",
      "    \n",
      "    SVD is usually described for the factorization of a 2D matrix :math:`A`.\n",
      "    The higher-dimensional case will be discussed below. In the 2D case, SVD is\n",
      "    written as :math:`A = U S V^H`, where :math:`A = a`, :math:`U= u`,\n",
      "    :math:`S= \\mathtt{np.diag}(s)` and :math:`V^H = vh`. The 1D array `s`\n",
      "    contains the singular values of `a` and `u` and `vh` are unitary. The rows\n",
      "    of `vh` are the eigenvectors of :math:`A^H A` and the columns of `u` are\n",
      "    the eigenvectors of :math:`A A^H`. In both cases the corresponding\n",
      "    (possibly non-zero) eigenvalues are given by ``s**2``.\n",
      "    \n",
      "    If `a` has more than two dimensions, then broadcasting rules apply, as\n",
      "    explained in :ref:`routines.linalg-broadcasting`. This means that SVD is\n",
      "    working in \"stacked\" mode: it iterates over all indices of the first\n",
      "    ``a.ndim - 2`` dimensions and for each combination SVD is applied to the\n",
      "    last two indices. The matrix `a` can be reconstructed from the\n",
      "    decomposition with either ``(u * s[..., None, :]) @ vh`` or\n",
      "    ``u @ (s[..., None] * vh)``. (The ``@`` operator can be replaced by the\n",
      "    function ``np.matmul`` for python versions below 3.5.)\n",
      "    \n",
      "    If `a` is a ``matrix`` object (as opposed to an ``ndarray``), then so are\n",
      "    all the return values.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.random.randn(9, 6) + 1j*np.random.randn(9, 6)\n",
      "    >>> b = np.random.randn(2, 7, 8, 3) + 1j*np.random.randn(2, 7, 8, 3)\n",
      "    \n",
      "    Reconstruction based on full SVD, 2D case:\n",
      "    \n",
      "    >>> U, S, Vh = np.linalg.svd(a, full_matrices=True)\n",
      "    >>> U.shape, S.shape, Vh.shape\n",
      "    ((9, 9), (6,), (6, 6))\n",
      "    >>> np.allclose(a, np.dot(U[:, :6] * S, Vh))\n",
      "    True\n",
      "    >>> smat = np.zeros((9, 6), dtype=complex)\n",
      "    >>> smat[:6, :6] = np.diag(S)\n",
      "    >>> np.allclose(a, np.dot(U, np.dot(smat, Vh)))\n",
      "    True\n",
      "    \n",
      "    Reconstruction based on reduced SVD, 2D case:\n",
      "    \n",
      "    >>> U, S, Vh = np.linalg.svd(a, full_matrices=False)\n",
      "    >>> U.shape, S.shape, Vh.shape\n",
      "    ((9, 6), (6,), (6, 6))\n",
      "    >>> np.allclose(a, np.dot(U * S, Vh))\n",
      "    True\n",
      "    >>> smat = np.diag(S)\n",
      "    >>> np.allclose(a, np.dot(U, np.dot(smat, Vh)))\n",
      "    True\n",
      "    \n",
      "    Reconstruction based on full SVD, 4D case:\n",
      "    \n",
      "    >>> U, S, Vh = np.linalg.svd(b, full_matrices=True)\n",
      "    >>> U.shape, S.shape, Vh.shape\n",
      "    ((2, 7, 8, 8), (2, 7, 3), (2, 7, 3, 3))\n",
      "    >>> np.allclose(b, np.matmul(U[..., :3] * S[..., None, :], Vh))\n",
      "    True\n",
      "    >>> np.allclose(b, np.matmul(U[..., :3], S[..., None] * Vh))\n",
      "    True\n",
      "    \n",
      "    Reconstruction based on reduced SVD, 4D case:\n",
      "    \n",
      "    >>> U, S, Vh = np.linalg.svd(b, full_matrices=False)\n",
      "    >>> U.shape, S.shape, Vh.shape\n",
      "    ((2, 7, 8, 3), (2, 7, 3), (2, 7, 3, 3))\n",
      "    >>> np.allclose(b, np.matmul(U * S[..., None, :], Vh))\n",
      "    True\n",
      "    >>> np.allclose(b, np.matmul(U, S[..., None] * Vh))\n",
      "    True\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__bool__',\n",
       " '__ceil__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floor__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__le__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__trunc__',\n",
       " '__xor__',\n",
       " 'as_integer_ratio',\n",
       " 'bit_count',\n",
       " 'bit_length',\n",
       " 'conjugate',\n",
       " 'denominator',\n",
       " 'from_bytes',\n",
       " 'imag',\n",
       " 'numerator',\n",
       " 'real',\n",
       " 'to_bytes']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python 内置方法访问package结构及其用法\n",
    "dir(np.linalg) # 访问package结构\n",
    "help(np.linalg.svd) # 访问具体用法\n",
    "dir(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcb83427-da0c-4d1a-a639-c2c2fd301c79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (365733421.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[58], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt?? # ipython魔法命令访问更清晰的用法\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "plt?? # ipython魔法命令访问更清晰的用法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce7ea0f-c6c1-4532-be59-3e8e17874fe6",
   "metadata": {},
   "source": [
    "## 2. 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba15e67-ec57-4d8e-b398-c5de52c5e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6bee31-00c7-40c0-8982-56386dd82d5e",
   "metadata": {},
   "source": [
    "learning 领域，数据从原始数据load进来的流程： \n",
    "\n",
    "`原始数据`(有垃圾数据，有用数据) -> `Dataset预处理数据`(存储有用数据及其label) -> `Dataloader适应训练格式的数据`(以适应训练和访问和访问的形式存储，如batch) -> `nn网络`(训练)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4e012-7641-4585-9354-1f62bbed9b6c",
   "metadata": {},
   "source": [
    "### 2.1 Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ad267d-4eab-4030-8810-ca7cb9b6bf1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m    从Dataset里继承创建适用于supervised learning的数据预处理类\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m \n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyData_folder\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    ├── train\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    │   ├── ants\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m        └── bees\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 读取 data_path, label_path\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    从Dataset里继承创建适用于supervised learning的数据预处理类\n",
    "''' \n",
    "\n",
    "class MyData_folder(Dataset):\n",
    "    '''\n",
    "    ├── train\n",
    "    │   ├── ants\n",
    "    │   └── bees\n",
    "    └── val\n",
    "        ├── ants\n",
    "        └── bees\n",
    "    '''\n",
    "    # 读取 data_path, label_path\n",
    "    def __init__(self, root_dir, label):\n",
    "        self.root_dir = root_dir\n",
    "        self.label = label\n",
    "        self.img_dir = os.path.join(self.root_dir, self.label)\n",
    "        self.img_name_list = os.listdir(self.img_dir)\n",
    "\n",
    "    # 返回 data, label\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_name_list[idx]\n",
    "        img_path = os.path.join(self.root_dir, self.label, img_name)\n",
    "        img_PIL = Image.open(img_path)\n",
    "        label = self.label\n",
    "        return img_PIL, label\n",
    "\n",
    "    # 返回 一类数据的大小\n",
    "    def __len__(self):\n",
    "        return len(self.img_name_list)\n",
    "\n",
    "# \n",
    "class MyData_label(Dataset):\n",
    "    '''\n",
    "    └── ├── train\n",
    "    │   ├── ants_image\n",
    "    │   ├── ants_label\n",
    "    │   ├── bees_image\n",
    "    │   └── bees_label\n",
    "    └── val\n",
    "        ├── ants_image\n",
    "        ├── ants_label\n",
    "        ├── bees_image\n",
    "        └── bees_label\n",
    "    '''\n",
    "\n",
    "    def __init__(self, img_dir, label_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_name_list = os.listdir(self.img_dir)\n",
    "        self.label_file_list= os.listdir(self.label_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_name_list[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        img_data = Image.open(img_path)\n",
    "\n",
    "        label_file_name = self.label_file_list[idx]\n",
    "        label_file_path = os.path.join(self.label_dir, label_file_name)\n",
    "        with open(label_file_path, 'r') as f:\n",
    "            label = f.read()\n",
    "\n",
    "        return img_data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa135afe-95a9-415c-a212-ea294ba563cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The num of total train data: 245\n",
      "The num of total val data: 153\n"
     ]
    }
   ],
   "source": [
    "# load data from MyData_folder\n",
    "root_dir = 'dataset/train/'\n",
    "ants_label_dir = 'ants'\n",
    "bees_label_dir = 'bees'\n",
    "\n",
    "ants_dataset_train = MyData_folder(root_dir, ants_label_dir)\n",
    "bees_dataset_train = MyData_folder(root_dir, bees_label_dir)\n",
    "\n",
    "# load data from MyData_label\n",
    "ants_dir = 'dataset_mod/val/ants_image/'\n",
    "bees_dir = 'dataset_mod/val/bees_image/'\n",
    "ants_label_dir = 'dataset_mod/val/ants_label/'\n",
    "bees_label_dir = 'dataset_mod/val/bees_label/'\n",
    "\n",
    "ants_dataset_val = MyData_label(ants_dir, ants_label_dir)\n",
    "bees_dataset_val = MyData_label(bees_dir, bees_label_dir)\n",
    "\n",
    "# 如何使用新设的Dataset类\n",
    "img_train, label = ants_dataset_train[1]\n",
    "img_train.show()\n",
    "\n",
    "img_val, label = ants_dataset_val[1]\n",
    "img_val.show()\n",
    "\n",
    "# 对数据进行拼接（多用于数据不足的情况）- 继承Dataset的原始能力\n",
    "train_dataset = ants_dataset_train + bees_dataset_train\n",
    "print(f'The num of total train data: {len(train_dataset)}')\n",
    "val_dataset = ants_dataset_val + bees_dataset_val\n",
    "print(f'The num of total val data: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c1b3c-6436-4fb9-8e9b-a9d4c0560f34",
   "metadata": {},
   "source": [
    "### 2.2 处理数据存放和路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a901435-49b1-4676-9c66-3a3fef9a4ff7",
   "metadata": {},
   "source": [
    "简单路径处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9879430d-18e1-4801-a2bb-c2629417bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = r'/home/haoran/pytorch/dataset/train/ants'\n",
    "img_path_list = os.listdir(dir_path)\n",
    "img_path_list[0]\n",
    "\n",
    "root_dir = 'dataset/train'\n",
    "label_dir = 'ants'\n",
    "path = os.path.join(root_dir, label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014bd60-9e3a-4d89-ab8f-e7cf73b9a99a",
   "metadata": {},
   "source": [
    "将文件格式从folder改为但张图片label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfb31344-55cd-4937-bba2-5f4367a6111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_img_num(img_path: str)-> bool:\n",
    "    img_name_list = os.listdir(img_path)\n",
    "    try:\n",
    "        for i, img_name in enumerate(img_name_list):\n",
    "            # get old path of imgs\n",
    "            img_old_path = os.path.join(img_path, img_name)\n",
    "            \n",
    "            # get new path of imgs\n",
    "            new_img_name = f'{i}{os.path.splitext(img_name)[1]}'\n",
    "            img_new_path = os.path.join(img_path, new_img_name)\n",
    "    \n",
    "            # rename old path with new path\n",
    "            os.rename(img_old_path, img_new_path)\n",
    "        print('Rename successfully')\n",
    "    except: \n",
    "        print('Rename failed')\n",
    "\n",
    "def create_label_dir(img_path: str, des_name: str, label:str)-> bool:\n",
    "    # make a new label folder\n",
    "    parent_dir = os.path.dirname(img_path)\n",
    "    des_path = os.path.join(parent_dir, des_name)\n",
    "    if not os.path.exists(des_path):\n",
    "        os.makedirs(des_path)\n",
    "        \n",
    "    # create label file '.txt'\n",
    "    num_of_label = len(os.listdir(img_path))\n",
    "    for i in range(num_of_label):\n",
    "        file_name = f\"{i}.txt\"  \n",
    "        file_path = os.path.join(des_path, file_name)\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(label)\n",
    "            \n",
    "    print('Add label successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2663f36d-c62c-4cfb-b60c-56cb7c8f575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename successfully\n"
     ]
    }
   ],
   "source": [
    "img_path = 'dataset_mod/train/bees_image'\n",
    "rename_img_num(img_path)\n",
    "\n",
    "img_path = 'dataset_mod/train/bees_image'\n",
    "des_namlabele = 'bees_label'\n",
    "label = 'bees'\n",
    "create_label_dir(img_path, des_name, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a7ea8c-b7df-4671-b9d1-a6bdc35fcfe5",
   "metadata": {},
   "source": [
    "## 3. 训练可视化 - Tensorboard的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1521e7ce-6b6e-4f25-8e08-e29b8afba059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ac0f0b6b-cec6-4fba-863b-6c9c77987452",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('logs')\n",
    "for i in range(100):\n",
    "    img_path = f'dataset_mod/train/bees_image/{i}.jpg'\n",
    "    img_PIL = Image.open(img_path)\n",
    "    img_array = np.array(img_PIL)\n",
    "    writer.add_image('test', img_array, i, dataformats='HWC')\n",
    "\n",
    "# y = 2x\n",
    "for i in range (100):\n",
    "    writer.add_scalar('y = 4x', 4*i, i)\n",
    "writer.close()\n",
    "\n",
    "# 命令行查看： tensorboard --logdir=logs --port=6006\n",
    "# 同一次训练，不同rollout存在同一文件夹下不同文件中\n",
    "# 不同次训练，分属不同1命名的文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf8a139-d6d7-4146-b5e5-765be9595538",
   "metadata": {},
   "source": [
    "## 4. 图像预处理 - Transforms的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db6bdc-55a2-4cb6-ba59-48888d10866c",
   "metadata": {},
   "source": [
    "`torchvision.transforms` 库是 PyTorch 中专门用于图像预处理的模块。它提供了**一系列常用的图像转换操作**，这些操作可以方便地对 `PIL` 图像、`NumPy` 数组或 PyTorch 张量进行处理。`transforms` 库中的操作主要用于在深度学习任务中对数据进行**预处理和增强**，比如图像的缩放、裁剪、归一化等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b2ac96-d1d7-47da-b7e3-0d5c916c210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e2725-0182-4d28-8ab3-892d6a2d39bd",
   "metadata": {},
   "source": [
    "使用流程：从`transforms`库中取出原子功能 -> 构建具体的工具 -> 将`opencv`或者`PIL`读取的图片先转换为`tensor`再放进工具里 -> 输出\n",
    "\n",
    "使用技巧： 关注输入和输出, 关注参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb95dc8b-fef9-47b4-bac4-83fbed520007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出原子功能 -> 构建具体的工具\n",
    "img_to_tensor = transforms.ToTensor()\n",
    "# 读取的图片\n",
    "img_PIL = Image.open(f'dataset_mod/train/bees_image/1.jpg')\n",
    "img_cv2 = cv2.imread(f'dataset_mod/train/bees_image/1.jpg')\n",
    "# ToTensor (将opencv或者PIL读取的图片放进工具里 -> 输出)\n",
    "img_tensor1 = img_to_tensor(img_PIL)\n",
    "img_tensor2 =  img_to_tensor(img_cv2)\n",
    "# tensor包含用于学习的大量参数\n",
    "writer = SummaryWriter('imgs')\n",
    "writer.add_image('Tensor_img1', img_tensor1) # tensorboard最好传入tensor数据类型\n",
    "writer.add_image('Tensor_img2', img_tensor2)\n",
    "\n",
    "# Normalize \n",
    "trans_norm = transforms.Normalize([0.05, 0.5, 0.5], [0.5, 0.5, 0.5]) # first_p: mean, second_p = std\n",
    "img_norm = trans_norm(img_tensor1)\n",
    "writer.add_image('Norm_img', img_norm)\n",
    "\n",
    "# Resize \n",
    "trans_resize = transforms.Resize((512, 512)) # transforms.Resize(512)\n",
    "img_resize = trans_resize(img_tensor1)\n",
    "writer.add_image('Resize_img', img_resize)\n",
    "\n",
    "# Compose \n",
    "trans_compose = transforms.Compose([img_to_tensor, trans_norm, trans_resize]) # 输入list包含transforms对象\n",
    "img_compose = trans_compose(img_PIL)\n",
    "writer.add_image('Compose_img', img_compose)\n",
    "\n",
    "# RandomCrop\n",
    "trans_random = transforms.RandomCrop(100)\n",
    "trans_compose2 = transforms.Compose([trans_random, img_to_tensor]) # 先crop在tensor\n",
    "for i in range(100):\n",
    "    img_crop = trans_compose2(img_PIL)\n",
    "    writer.add_image('RandCrop_img', img_crop, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9f49dc-df2a-47e3-81f9-85be7e0462bc",
   "metadata": {},
   "source": [
    "## 5. 标准数据集 - torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9deb242e-6458-4ebd-9a46-5e4f1cf1fb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7FE16BD15C60>, 6)\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FE16BDAE8C0>\n",
      "3\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "# CIFAR10\n",
    "train_set = torchvision.datasets.CIFAR10(root='./datasets', train=True, download=True) # 默认数据类型为PIL\n",
    "test_set = torchvision.datasets.CIFAR10(root='./datasets', train=False, download=True)\n",
    "print(train_set[0])\n",
    "print(train_set.classes)\n",
    "\n",
    "img, target = test_set[0]\n",
    "print(img)\n",
    "print(target)\n",
    "print(test_set.classes[target])\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b552539-e022-4228-950c-3741719563e9",
   "metadata": {},
   "source": [
    "## 6. 训练数据导入前的打包 - Dataloader类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "189e8597-ef59-405b-8fcc-db5d9a230169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23092328-ff77-4732-aa81-ff9c7dce5cbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|████████████████████████████████| 156/156 [00:03<00:00, 46.86it/s]\n",
      "epoch 2: 100%|████████████████████████████████| 156/156 [00:03<00:00, 46.53it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = torchvision.datasets.CIFAR10('./datasets', train = False, transform=torchvision.transforms.ToTensor())\n",
    "img, target = test_data[0]\n",
    "print(img.shape)\n",
    "print(test_data.classes[target])\n",
    "\n",
    "# 对数据集进行打包\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False, num_workers=0, drop_last=True)\n",
    "'''\n",
    "    img0, target0 = dataset[0]\n",
    "    img1, target1 = dataset[1]\n",
    "    img2, target2 = dataset[2]\n",
    "    img3, target3 = dataset[3]\n",
    "    ...\n",
    "    ---------------------------\n",
    "    imgs, targets = dataset[:4]\n",
    "'''\n",
    "writer = SummaryWriter('dataloader')\n",
    "for epoch in range(1, 1+2):\n",
    "    for step, data in enumerate(tqdm(test_loader, desc=f'epoch {epoch}')):\n",
    "        imgs, targets = data\n",
    "        # print(imgs.shape)\n",
    "        # print(targets)\n",
    "        writer.add_images(f'test_data_drop_last: {epoch}', imgs, step)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d7589-f50a-402c-9a90-83b8f238f3c7",
   "metadata": {},
   "source": [
    "## 7. 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d0e4d9-a0d1-422a-b166-f34034d3e029",
   "metadata": {},
   "source": [
    "### 7.1 神经网络的基本骨架 - nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd79c0f9-cb8a-40c9-b26b-9fbbfa2d19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45edc48d-f849-4180-a328-65273a741dcf",
   "metadata": {},
   "source": [
    "### 7.2 神经网络 - 卷积层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98fc6c02-2305-4a71-b0d7-f98348a39aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[13, 10, 12],\n",
      "          [12, 14, 19],\n",
      "          [13, 13, 10]]]])\n",
      "tensor([[[[13, 12],\n",
      "          [13, 10]]]])\n",
      "tensor([[[[ 2,  6,  5,  8,  8],\n",
      "          [ 7, 13, 10, 12, 11],\n",
      "          [ 7, 12, 14, 19, 14],\n",
      "          [ 8, 13, 13, 10, 11],\n",
      "          [ 5, 11, 11, 13,  8]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# The 2D convolution (conv2d) in PyTorch expects a 4D input tensor with the following shape:\n",
    "'''(N, C_in, H, W)\n",
    "    N: Batch size (number of input samples in a batch)\n",
    "    C_in: Number of input channels (e.g., 1 for grayscale images, 3 for RGB images)\n",
    "    H: Height of the input (number of rows)\n",
    "    W: Width of the input (number of columns)\n",
    "'''\n",
    "input = torch.tensor([[1, 2, 0, 3, 1],\n",
    "                      [1, 2, 1, 3, 1],\n",
    "                      [2, 2, 0, 2, 1],\n",
    "                      [1, 2, 3, 3, 2],\n",
    "                      [1, 3, 0, 2, 1]]).reshape(1, 1, 5, 5)\n",
    "\n",
    "kernel = torch.tensor([[1, 2, 1],\n",
    "                       [0, 1, 0],\n",
    "                       [2, 1, 0]]).reshape(1, 1, 3, 3)\n",
    "\n",
    "output = F.conv2d(input, kernel, stride=1)\n",
    "print(output)\n",
    "\n",
    "output1 = F.conv2d(input, kernel, stride=2)\n",
    "print(output1)\n",
    "\n",
    "output2 = F.conv2d(input, kernel, stride=1, padding=1)\n",
    "print(output2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
